{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Dynatrace Observability Lab: OpenTelemetry Cleanup","text":"<p>Support Policy</p> <p>This is a demo project created by the Developer Relations team at Dynatrace, showcasing integrations with open source technologies.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p> <p>View the Code</p> <p>The code for this repository is hosted on GitHub. Click the \"View Code on GitHub\" link above.</p> <p>OpenPipeline</p> <p>If you prefer to process data on-cluster without deploying infrastructure, we suggest using Dynatrace OpenPipeline.</p> <p></p> <p>There is a lot of telemetry data. Reducing, removing and standardising the telemetry data that you ingest will save cost, increase signal to noise ratio and help make your Observability platform a cleaner, more useful place.</p> <p>This hands on Observability Lab will demonstrate various tips and tricks on how to achieve a clean, standardised telemetry ingest using when you send data via the Dynatrace Collector:</p> <ul> <li>Logs: Batching</li> <li>Logs: Including file and Operating System information</li> <li>Logs: Correcting timestamps</li> <li>Logs: Setting default severity / status</li> <li>Logs: Setting severity / status based on log line content</li> <li>Logs: Adding Key/Value attributes based on log line content</li> <li>Logs: Dynamic rewriting of log content for standardisation</li> <li>Logs: Dropping logs based on log content</li> </ul> <p>The Dynatrace collector is a fully supported distribution of the open source upstream OpenTelemetry collector. The Dynatrace collector contains no vendor specific components.</p>"},{"location":"#compatibility","title":"Compatibility","text":"Deployment Tutorial Compatible Dynatrace Managed \u2714\ufe0f Dynatrace SaaS \u2714\ufe0f <ul> <li>Click here to begin </li> </ul>"},{"location":"cleanup/","title":"8. Cleanup","text":"<p>To cleanup resources, go to https://github.com/codespaces and delete the codespace.</p> <p>You may also want to deactivate or delete the API token.</p>"},{"location":"getting-started/","title":"2. Getting Started","text":"<p>You will need to collect some information before you can begin.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Dynatrace tenant (sign up for a free trial)</li> <li>A Dynatrace API token with <code>logs.ingest</code> permissions (see below)</li> </ul>"},{"location":"getting-started/#format-url","title":"Format URL","text":"<p>Make a note of your Dynatrace tenant ID. It is the first bit of your URL (eg. <code>abc12345</code> in the following examples):</p> <pre><code>https://abc12345.live.dynatrace.com\nhttps://abc12345.apps.dynatrace.com\n</code></pre>"},{"location":"getting-started/#environment-type","title":"Environment Type","text":"<p>Make a note of your environment type. The above environment type is <code>live</code>. If in doubt, use <code>live</code>.</p>"},{"location":"getting-started/#create-api-token","title":"Create API Token","text":"<p>In Dynatrace:</p> <ul> <li>Press <code>ctrl + k</code> and search for <code>access tokens</code></li> <li>Create a new access token with the <code>logs.ingest</code> permission</li> </ul> <p>You have all the necessary details and are ready to get started.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"resources/","title":"9. Resources","text":"<p>TODO</p>"},{"location":"scenario1/","title":"Batching Telemetry","text":"<p>In order to reduce load on both the collector and Dynatrace, you most likely do not want to send every log line individually.</p> <p>Rather, the log lines should be bundled and sent to Dynatrace in batches.</p> <p>scenario1.yaml shows the OpenTelemetry collector configuration to achieve this.</p> <p>We will first generate the data then explain the YAML configuration.</p>"},{"location":"scenario1/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario1.yaml\n</code></pre>"},{"location":"scenario1/#generate-log-data","title":"Generate Log Data","text":"<p>Open the empty <code>file.log</code> file and add this line then save the file.</p> <pre><code>My first dummy log line...\n</code></pre>"},{"location":"scenario1/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify that the filelog receiver has sent the data to the collector. You should see terminal output like this:</p> <pre><code>...\n2025-03-26T06:49:00.944Z        info    Logs    {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\", \"resource logs\": 1, \"log records\": 1}\n2025-03-26T06:49:00.944Z        info    ResourceLog #0\nResource SchemaURL: \nScopeLogs #0\nScopeLogs SchemaURL: \nInstrumentationScope  \nLogRecord #0\nObservedTimestamp: 2025-03-26 06:48:59.538241971 +0000 UTC\nTimestamp: 1970-01-01 00:00:00 +0000 UTC\nSeverityText: \nSeverityNumber: Unspecified(0)\nBody: Str(My first dummy log line...)\nAttributes:\n     -&gt; log.file.name: Str(file.log)\nTrace ID: \nSpan ID: \nFlags: 0\n        {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\"}\n</code></pre>"},{"location":"scenario1/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>In Dynatrace:</p> <ul> <li>Press <code>ctrl + k</code> and search for <code>notebooks</code></li> <li>Create a new notebook and add a new DQL tile with this code: <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n</code></pre></li> </ul> <p>Notice that the batching was entirely transparent to you.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario10/","title":"Enrich with Ownership","text":"<p>Adding ownership information to logs is critical to enable downstream usecases and further automation. If you know where a log comes from and who \"owns\" it (in other words, who can help action or fix the issue) that becomes very powerful for cross-charging Observability data ingest, automation, triggering workflows and AI agents.</p> <p>In the prior scenarios, logs were being enriched line by line. Often though, you'll know that one team / department is responsbile for an entire log file (or set of log files). In this case, it makes sense to enrich at the log file level. The configuration is simpler and easier to read.</p> <p>Imagine that the <code>file.log</code> file (and every log line that comes from it:</p> <ul> <li>Is owned by <code>TeamA</code></li> <li>Has an email address of <code>team@example.com</code> for support / issues</li> <li><code>teamA</code> has an team code of <code>ABC556D</code> (useful for cross-charging and ticket routing)</li> </ul> <p>scenario10.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario10/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario10/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario10.yaml\n</code></pre>"},{"location":"scenario10/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add these two lines then save the file.</p> <pre><code>My eleventh dummy log line\n</code></pre>"},{"location":"scenario10/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p> <p></p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n| fieldsKeep timestamp, content, loglevel, team.name, team.email, team.chargecode \n| sort timestamp desc\n</code></pre> <p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Congratulations! Every log line from <code>file.log</code> will be automatically enriched with the team details.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario2/","title":"Add File and OS Information","text":"<p>It is usually important to know where the log lines are coming from. This helps fault domain isolation and enables quickly routing the problem to the relevant owner / team.</p> <p>In this scenario, the collector will be used to enrich the log lines to include the following information on each log line:</p> <ul> <li>Hostname</li> <li>Operating system type</li> <li>Log file name</li> <li>Log file path</li> </ul> <p>scenario2.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario2/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario2/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario2.yaml\n</code></pre>"},{"location":"scenario2/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add this line then save the file.</p> <pre><code>My second dummy log line...\n</code></pre>"},{"location":"scenario2/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify that the filelog receiver has sent the data to the collector. You should see terminal output like this:</p> <pre><code>...\n2025-03-27T06:04:05.900Z        info    ResourceLog #0\nResource SchemaURL: https://opentelemetry.io/schemas/1.6.1\nResource attributes:\n     -&gt; host.name: Str(codespaces-3655f4)\n     -&gt; os.type: Str(linux)\n...\nBody: Str(My second dummy log line...)\nAttributes:\n     -&gt; log.file.name: Str(file.log)\n     -&gt; log.file.path: Str(/workspaces/demo-opentelemetry-cleanup/file.log)\n</code></pre> <p>Notice that <code>host.name</code> and <code>os.type</code> have been added as resource attributes. The collector performed this lookup and attached them automatically. Notice too that the log record has new attributes of <code>log.file.name</code> and <code>log.file.path</code>.</p>"},{"location":"scenario2/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p> <p></p> <p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Reminder, the DQL statement is:</p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n</code></pre> <p>Congratulations! The log lines are now automatically enriched with important host-level information.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario3/","title":"Set Timestamps","text":"<p>The log lines ingested from scenario 1 and scenario 2 contain no timestamps.</p> <p>The collector and Dynatrace will make a best-effort guesses at the correct timestamp, but it is always best to set the timestamps explicitly.</p> <p>To do this we will tell the collector to set two fields: <code>timestamp</code> and <code>observed timestamp</code> to the current timestamp (ie. <code>Now</code>).</p> <p>scenario3.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario3/#look-again","title":"Look Again","text":"<p>Look again at the collector debug output from scenario 2. You should see that the timestamp is actually set to 1970.</p> <pre><code>LogRecord #1\nObservedTimestamp: 2025-03-27 06:04:05.298857978 +0000 UTC\nTimestamp: 1970-01-01 00:00:00 +0000 UTC\nSeverityText: \nSeverityNumber: Unspecified(0)\nBody: Str(My second dummy log line...)\nAttributes:\n     -&gt; log.file.name: Str(file.log)\n     -&gt; log.file.path: Str(/workspaces/demo-opentelemetry-cleanup/file.log)\n</code></pre>"},{"location":"scenario3/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario3/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario3.yaml\n</code></pre>"},{"location":"scenario3/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add this line then save the file.</p> <pre><code>My third dummy log line...\n</code></pre>"},{"location":"scenario3/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify that the <code>timestamp</code> and <code>observed timestamp</code> fields are now correctly set to the current time and date:</p> <pre><code>...\nObservedTimestamp: 2025-03-27 06:28:50.507084067 +0000 UTC\nTimestamp: 2025-03-27 06:28:50.507083807 +0000 UTC\nSeverityText: \nSeverityNumber: Unspecified(0)\nBody: Str(My third dummy log line...)\n...\n</code></pre>"},{"location":"scenario3/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Reminder, the DQL statement is:</p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n</code></pre> <p>Congratulations! The log lines now have the correct timestamps.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario4/","title":"Setting default severity / status","text":"<p>The log lines ingested from the previous scenarious contain no severity information (eg. <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code>, <code>ERROR</code> etc).</p> <p>Setting the correct log severity is important for downstream users to understand how \"bad\" the log line is - is it simply an informational message or a serious error?</p> <p>These severities will also be used in later scenarios to (for example) conditionally drop or re-route logs based on their severity.</p> <p>For now, let's assume that, where a severity is not explicitly set (all of our log lines), we want to default the lines to an <code>INFO</code> level log line.</p> <p>scenario4.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario4/#look-again","title":"Look Again","text":"<p>Look again at the collector debug output from scenario 3. You should see that the <code>SeverityText</code> and <code>SeverityNumber</code> are both empty / unspecified.</p> <pre><code>LogRecord #1\nObservedTimestamp: 2025-03-27 06:04:05.298857978 +0000 UTC\nTimestamp: 1970-01-01 00:00:00 +0000 UTC\nSeverityText: \nSeverityNumber: Unspecified(0)\nBody: Str(My third dummy log line...)\nAttributes:\n     -&gt; log.file.name: Str(file.log)\n     -&gt; log.file.path: Str(/workspaces/demo-opentelemetry-cleanup/file.log)\n</code></pre>"},{"location":"scenario4/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario4/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario4.yaml\n</code></pre>"},{"location":"scenario4/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add this line then save the file.</p> <pre><code>My fourth dummy log line...\n</code></pre>"},{"location":"scenario4/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify that the <code>SeverityText</code> and <code>SeverityNumber</code> fields are now correctly set:</p> <pre><code>...\nSeverityText: INFO\nSeverityNumber: Info(9)\nBody: Str(My fourth dummy log line...)\n...\n</code></pre>"},{"location":"scenario4/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p> <p></p> <p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Reminder, the DQL statement is:</p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n</code></pre> <p>Congratulations! The log lines now have the correct timestamps.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario5/","title":"Setting severity / status based on log content","text":"<p>On occasion, you will need to adjust the severity of the log based on the actual log line content.</p> <p>For example, a log line that reads: <code>Please investigate - something is broken</code> is mistakenly sent as an <code>INFO</code> level event when it really should be an <code>ERROR</code>.</p> <p>scenario5.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario5/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario5/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario5.yaml\n</code></pre>"},{"location":"scenario5/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add this line then save the file.</p> <pre><code>My fifth dummy log line. Please investigate - something is broken.\n</code></pre>"},{"location":"scenario5/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify that the <code>SeverityText</code> and <code>SeverityNumber</code> fields are now correctly set.</p> <pre><code>...\nSeverityText: ERROR\nSeverityNumber: Error(17)\nBody: Str(My fifth dummy log line. Please investigate - something is broken.)\n...\n</code></pre>"},{"location":"scenario5/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p> <p></p> <p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Reminder, the DQL statement is:</p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n</code></pre> <p>Congratulations! The log lines now have the most appropriate log level.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario6/","title":"Creating Attributes based on log content","text":"<p>One of the benefits of an OpenTelemetry log is that it is structured. Rather than just a single log line with some text, the collector transforms it into a structured object (eg. JSON).</p> <p>This makes it possible to attach new <code>attributes</code> to a log line. These attributes are key/value pairs of information that you care about.</p> <p>In this scenario, you will add a new Key/Value attribute conditionally based on the content of the log line.</p> <p>Imagine this log line:</p> <pre><code>My dummy log line from userId=123 part of userTier=tier1\n</code></pre> <p>That is somewhat useful, but it is probably more useful for a human if we instantly know that <code>tier1</code> customers qualify for the <code>gold</code> level support tier.</p> <p>The OpenTelemetry collector can read the log line and add a new Key/Value pair: <pre><code>support.tier: gold\n</code></pre></p> <p>when the log line contains <code>userTier=tier1</code>. <code>userTier2 == silver</code> and <code>userTier3 == bronze</code> and so on.</p> <p>scenario6.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario6/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario6/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario6.yaml\n</code></pre>"},{"location":"scenario6/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add this line then save the file.</p> <pre><code>My sixth dummy log line from userId=123 part of userTier=tier1\n</code></pre>"},{"location":"scenario6/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify that the <code>support.tier</code> attribute has been added:</p> <pre><code>...\nBody: Str(My sixth dummy log line from userId=123 part of userTier=tier1)\nAttributes:\n     -&gt; log.file.name: Str(file.log)\n     -&gt; log.file.path: Str(/workspaces/demo-opentelemetry-cleanup/file.log)\n     -&gt; support.tier: Str(gold)\n...\n</code></pre>"},{"location":"scenario6/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p> <p></p> <p>There are a lot of columns shown so either scroll all the way to the right to see the <code>support.tier</code> column.</p> <p>Or cleanup the columns by choosing to keep only certain columns:</p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n| fieldsKeep timestamp, content, host.name, log.file.name, log.file.path, os.type, support.tier\n</code></pre> <p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Congratulations! You can now add any important Key/Value information as logs flow through the collector.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario7/","title":"Dynamically Re-writing log lines for standardisation","text":"<p>Imagine a new starter joins the development team.</p> <p>They are informed of the team standards - that logs with <code>userTier=...</code> are required to make the Observability system work.</p> <p>However, they forget and so write their logs with <code>user.tier=...</code> instead.</p> <p>Question</p> <p>Can the OpenTelemetry collector fix this?</p> <p>Yes! The transform processor can be used to rewrite the log line in real time so <code>user.tier</code> becomes <code>userTier</code> with this statement:</p> <pre><code>replace_pattern(body, \"user.tier=\", \"userTier=\")\n</code></pre> <p>scenario7.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario7/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario7/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario7.yaml\n</code></pre>"},{"location":"scenario7/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add this line then save the file.</p> <pre><code>My seventh dummy log line from userId=4321 part of user.tier=tier3\n</code></pre>"},{"location":"scenario7/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify two things:</p> <ul> <li><code>user.tier</code> piece has been rewritten to <code>userTier</code></li> <li><code>support.tier</code> attribute has been added due to <code>userTier</code> being present in the log content</li> </ul> <pre><code>...\nBody: Str(My seventh dummy log line from userId=4321 part of userTier=tier3)\nAttributes:\n     ...\n     -&gt; support.tier: Str(bronze)\n...\n</code></pre>"},{"location":"scenario7/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p> <p></p> <p>There are a lot of columns shown so either scroll all the way to the right to see the <code>support.tier</code> column.</p> <p>Or cleanup the columns by choosing to keep only certain columns:</p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n| fieldsKeep timestamp, content, host.name, log.file.name, log.file.path, os.type, support.tier\n</code></pre> <p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Congratulations! You can now add any important Key/Value information as logs flow through the collector.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario8/","title":"Dropping Logs based on Content","text":"<p>Up to now, we have been processing and rewriting log content as it flows through the collector.</p> <p>What if instead, you simply want to drop any logs if they contain restricted content?</p> <p>In this scenario, to protect against Personally Identifiable Information (PII) capture, the filter processor will be used to drop any log lines containing the word <code>password</code> (case insensitive).</p> <p>scenario8.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario8/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario8/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario8.yaml\n</code></pre> <p>Ordering matters</p> <p>Notice the <code>service.pipelines.logs.processors</code> definition.</p> <p><code>filter</code> is defined first so log lines are filtered first before further processing.</p> <pre><code>processors: [filter, resourcedetection, transform, batch]\n</code></pre>"},{"location":"scenario8/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add this line then save the file.</p> <pre><code>My eighth dummy log line. The password is abc124\n</code></pre>"},{"location":"scenario8/#verify-debug-data-in-collector-output","title":"Verify Debug Data in Collector Output","text":"<p>View the collector terminal window and verify that there is absolutely no record of the offending line in the collector logs:</p> <ul> <li><code>user.tier</code> piece has been rewritten to <code>userTier</code></li> <li><code>support.tier</code> attribute has been added due to <code>userTier</code> being present in the log content</li> </ul> <pre><code>...\nBody: Str(My seventh dummy log line from userId=4321 part of userTier=tier3)\nAttributes:\n     ...\n     -&gt; support.tier: Str(bronze)\n...\n</code></pre>"},{"location":"scenario8/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>As you may expect, there is nothing to see in Dynatrace.</p> <p>Congratulations! You can now prevent logs from being persisted based on their content.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"scenario9/","title":"Only Keep Important Logs","text":"<p>Controlling Observability costs is important.</p> <p>In this scenario, only logs with a severity level of <code>WARN</code> or above (eg. <code>Warning</code>, <code>Error</code> or <code>Fatal</code>) Up to now, we have been processing and rewriting log content as it flows through the collector.</p> <p>scenario9.yaml shows the OpenTelemetry collector configuration to achieve this.</p>"},{"location":"scenario9/#stop-previous-collector","title":"Stop Previous Collector","text":"<p>If you haven't done so already, stop the previous collector process by pressing <code>Ctrl + C</code>.</p>"},{"location":"scenario9/#start-collector","title":"Start Collector","text":"<p>Run the following command to start the collector:</p> <pre><code>/workspaces/$RepositoryName/dynatrace-otel-collector --config=/workspaces/$RepositoryName/scenario9.yaml\n</code></pre> <p>Ordering matters</p> <p>Notice the <code>service.pipelines.logs.processors</code> definition.</p> <p>Unlike scenario 8, the logs are <code>transform</code>ed first then filtered.</p> <p>This is to ensure the logs have the correct severity level before a filtering decision is made.</p> <pre><code>processors: [resourcedetection, transform, filter, batch]\n</code></pre>"},{"location":"scenario9/#generate-log-data","title":"Generate Log Data","text":"<p>Open <code>file.log</code> file and add these two lines then save the file.</p> <pre><code>My ninth dummy log line.\nMy tenth dummy log line. Please investigate - something is broken\n</code></pre> <p>Only 1 log line received</p> <p>You should see only one of these lines in the collector &amp; Dynatrace.</p> <p>Both log lines have no explicit severity, but remember the collector rules create severities due to the transform processor.</p> <ul> <li>The first line: <code>My ninth dummy log line.</code> will be mapped to an <code>INFO</code> event.</li> <li>The second line: <code>My tenth dummy log line. Please investigate - something is broken</code> will be mapped to an <code>ERROR</code> event.</li> </ul> <p>Due to the filter processor rules, the <code>INFO</code> line will be dropped and ONLY the <code>ERROR</code> log line will be sent to Dynatrace.</p>"},{"location":"scenario9/#view-data-in-dynatrace","title":"View Data in Dynatrace","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p> <p></p> <pre><code>fetch logs\n| filter contains(content, \"dummy log line\")\n</code></pre> <p>Click the <code>Run</code> button again on the DQL tile. You should see the new data.</p> <p>Congratulations! You can now surgically decide on which log lines to store.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"start-demo/","title":"3. Start Demo","text":""},{"location":"start-demo/#start-demo","title":"Start Demo","text":"<p>Enter Required Information</p> <p>During the next step you will be prompted for some details.</p> <p>Enter the relevant details in the GitHub form.</p> <p>Click this button to launch the demo in a new tab.</p> <p>Provide the tenant ID and API token via the form. These will be encrypted and stored in GitHub. They will also automatically be set as environment variables in the codespace.</p> <p></p>"},{"location":"start-demo/#understand-demo-environment","title":"Understand Demo Environment","text":"<p>The Dynatrace OpenTelemetry Collector (<code>./dynatrace-otel-collector</code>) is automatically downloaded at startup. This collector distribution is officially supported by Dynatrace.</p> <p>The <code>filelog</code> receiver we will soon define (in a YAML file) will watch one or more log files and send the log lines to the collector.</p> <p>We will use the collector to process, enrich or drop data.</p> <p>The collector will then send (export) data into your Dynatrace environment.</p> <p>The collector requires a configuration file. There are different configuration files for different tasks. Each will be presented as a single \"scenario\" and explained as you proceed through this guide.</p>"},{"location":"start-demo/#understand-collector-configuration","title":"Understand Collector Configuration","text":"<p>Understanding the configuration of the collector is key to understanding how the data gets from your devices into Dynatrace.</p> <p>Note: You do not need to modify <code>scenario*.yaml</code> files.</p>"},{"location":"start-demo/#receivers","title":"Receivers","text":"<pre><code>receivers:\n  ...\n</code></pre> <p>The receivers block describes how data is received by the collector.</p> <p>In this case, the filelog receiver is configured to watch log files and ingest them into the collector.</p>"},{"location":"start-demo/#processors","title":"Processors","text":"<pre><code>processors:\n  ...\n</code></pre> <p>Processors live in the middle of the chain. They process the data in some way before it is sent out to the final destination.</p>"},{"location":"start-demo/#exporters","title":"Exporters","text":"<pre><code>exporters:\n  ...\n</code></pre> <p>The exporters block defines what happens to the data at the point it leaves the collector.</p> <p>In the following scenarios, 2 exporters are defined: <code>debug</code> and <code>otlphttp</code>. The <code>debug</code> exporter sends output to the collector console. It is included here as a training aid for the demo so you can see what's happening.</p> <p>The <code>otlphttp</code> exporter sends data to an endpoint in OpenTelemetry Protocol (OTLP) format via HTTPS. Dynatrace natively understands the OTLP format.</p> <p>Notice that two environment variables are referenced: <code>DT_ENDPOINT</code> and <code>DT_API_TOKEN</code> you may recall these from the form you completed when the codespace started.</p> <p>These environment variables are already set for you, so you don't need to do anything else.</p>"},{"location":"start-demo/#pipelines","title":"Pipelines","text":"<pre><code>service:\n  pipelines:\n    logs:\n      receivers: [filelog]\n      processors: [batch]\n      exporters: [debug, otlphttp]\n</code></pre> <p>The pipelines block defines how the collector components are connected in an end-to-end pipeline.</p> <p>In this case, <code>1</code> pipeline (dealing with log data) is defined. This pipeline will receive data using the <code>filelog</code> receiver, process the data using the <code>batch</code> processor (no prizes for what this does) and export it to both the <code>debug</code> and <code>otlphttp</code> exporters simultaneously.</p> <ul> <li>Click here to continue </li> </ul>"},{"location":"whats-next/","title":"10. What's Next?","text":"<p>TODO</p>"},{"location":"snippets/codespace-details-warning-box/","title":"Codespace details warning box","text":"<p>Enter Required Information</p> <p>During the next step you will be prompted for some details.</p> <p>Enter the relevant details in the GitHub form.</p>"},{"location":"snippets/disclaimer/","title":"Disclaimer","text":"<p>Support Policy</p> <p>This is a demo project created by the Developer Relations team at Dynatrace, showcasing integrations with open source technologies.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p>"},{"location":"snippets/enlarge-image-tip/","title":"Enlarge image tip","text":"<p>Tip</p> <p>Right click and \"open image in new tab\" to see large image</p>"},{"location":"snippets/openpipeline/","title":"Openpipeline","text":"<p>OpenPipeline</p> <p>If you prefer to process data on-cluster without deploying infrastructure, we suggest using Dynatrace OpenPipeline.</p>"},{"location":"snippets/view-code/","title":"View code","text":"<p>View the Code</p> <p>The code for this repository is hosted on GitHub. Click the \"View Code on GitHub\" link above.</p>"}]}